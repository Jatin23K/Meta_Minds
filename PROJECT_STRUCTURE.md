# üìÅ **META MINDS - Project Structure Documentation**

This document provides a comprehensive overview of the Meta Minds project structure, file organization, and component responsibilities.

---

## üèóÔ∏è **Overall Architecture** (v2.0 - 10/10 Rating)

```
1. META_MINDS/
‚îú‚îÄ‚îÄ üìÇ src/                   # Complete source code
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ core/              # Core analysis engine (v2.0)
‚îÇ       ‚îú‚îÄ‚îÄ main.py                    # Main orchestrator with CLI support
‚îÇ       ‚îú‚îÄ‚îÄ config.py                  # Configuration management
‚îÇ       ‚îú‚îÄ‚îÄ data_loader.py             # Multi-format data loading with safety limits
‚îÇ       ‚îú‚îÄ‚îÄ data_analyzer.py           # üÜï Intelligent column analysis
‚îÇ       ‚îú‚îÄ‚îÄ output_handler.py          # Report generation + export integration
‚îÇ       ‚îú‚îÄ‚îÄ emoji_utils.py             # üÜï Professional emoji system
‚îÇ       ‚îú‚îÄ‚îÄ export_utils.py            # üÜï Excel/JSON/HTML export functions
‚îÇ       ‚îú‚îÄ‚îÄ cli_handler.py             # üÜï CLI automation support
‚îÇ       ‚îú‚îÄ‚îÄ agents.py                  # CrewAI agent definitions
‚îÇ       ‚îú‚îÄ‚îÄ tasks.py                   # Task orchestration + question trimming
‚îÇ       ‚îú‚îÄ‚îÄ smart_question_generator.py # SMART engine with enhanced context
‚îÇ       ‚îú‚îÄ‚îÄ smart_validator.py         # Quality control & validation
‚îÇ       ‚îî‚îÄ‚îÄ context_collector.py       # 17 templates + 6 enhanced questions
‚îú‚îÄ‚îÄ üìÇ input/                 # Hybrid input system (3 template files)
‚îÇ   ‚îú‚îÄ‚îÄ Business_Background.txt    # Project context template
‚îÇ   ‚îú‚îÄ‚îÄ Dataset_Background.txt     # Dataset-specific context template
‚îÇ   ‚îî‚îÄ‚îÄ Message.txt               # Senior stakeholder instructions template
‚îú‚îÄ‚îÄ üìÇ dataset/               # Sample datasets (for testing)
‚îú‚îÄ‚îÄ üìÇ Output/                # Generated reports (git-ignored)
‚îÇ   ‚îú‚îÄ‚îÄ Individual_*.txt          # Individual dataset reports
‚îÇ   ‚îú‚îÄ‚îÄ Cross-Dataset_*.txt       # Cross-dataset comparison reports
‚îÇ   ‚îú‚îÄ‚îÄ *.xlsx                    # üÜï Excel exports
‚îÇ   ‚îú‚îÄ‚îÄ *.json                    # üÜï JSON exports
‚îÇ   ‚îî‚îÄ‚îÄ *.html                    # üÜï HTML dashboards
‚îú‚îÄ‚îÄ üìÇ docs/                  # Comprehensive documentation
‚îú‚îÄ‚îÄ üìÇ examples/              # Examples and demos
‚îú‚îÄ‚îÄ üìÇ workflows/             # Workflow definitions
‚îú‚îÄ‚îÄ üìÑ .gitignore             # Git ignore rules
‚îú‚îÄ‚îÄ üìÑ env.example            # Environment template
‚îú‚îÄ‚îÄ üìÑ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ üìÑ README.md              # Project documentation (v2.0)
‚îî‚îÄ‚îÄ üìÑ PROJECT_STRUCTURE.md   # This file
```

---

## üÜï **What's New in v2.0 (10/10 Upgrade)**

### **Major Enhancements:**

#### **1. üß† Intelligent Column Analysis**
- **Before**: "Column 'YEAR' with sample values: 2013, 2013, 2013"
- **After**: "Temporal identifier representing calendar year. Range: 2013-2023. Used for time-series analysis."
- **Impact**: Meaningful insights instead of repetitive data
- **Auto-detects**: 15+ column types with statistical context

#### **2. üñ•Ô∏è Full CLI Automation**
```bash
# Quick mode - zero prompts
python main.py --quick --datasets data.csv --questions 20 --export-all

# Config mode - reusable settings  
python main.py --config my_analysis.json

# Batch mode - multiple analyses
python main.py --batch config_folder/
```
- **Impact**: Enables automation, scripting, CI/CD integration

#### **3. üì§ Multiple Export Formats**
- **TXT**: Professional reports (default)
- **Excel**: Multi-sheet workbooks with metadata
- **JSON**: Structured data for APIs
- **HTML**: Interactive dashboards with copy buttons
- **Impact**: Flexibility for different stakeholders

#### **4. üéØ Exact Question Count Enforcement**
- **Before**: Request 13, get 15 (AI overgeneration)
- **After**: Request 13, get exactly 13 (forced trimming)
- **Impact**: Predictable output, no surprises

#### **5. üíé Professional Emoji System**
- **Auto-detects** terminal encoding (UTF-8 vs cp1252)
- **UTF-8 terminals**: Beautiful emojis (üöÄüìäüîç)
- **Windows cmd**: Professional text symbols (>>[CHART][SEARCH])
- **Impact**: No more Unicode encoding errors

#### **6. üè¢ Enhanced Context Collection**
- **6 optional deep-dive questions** for 9.5/10 quality
- **Intelligent quality ranges** (7.5-8.0, 8.5-9.0, 9.0-9.5)
- **Skip/Must-Have/All/Custom** selection modes
- **Impact**: Flexible quality levels based on need

#### **7. üìÅ Smart Output Management**
- Auto-detects correct Output folder location
- Multiple fallback directories if permission denied
- Shows exact file save location
- **Impact**: No more "file not found" issues

#### **8. üìä Intelligent Recommendations**
- Auto-calculates recommended question count
- Based on data complexity (columns, rows)
- Shows dataset preview before asking for counts
- **Impact**: Better decisions, less guessing

---

## üìÇ **Detailed Directory Structure**

### **üìÇ `src/core/` - Core Analysis Engine**

#### **üß† Core Processing Files**

| File | Purpose | Key Features | Dependencies |
|------|---------|--------------|--------------|
| **`main.py`** | üéØ **Main Orchestrator** | Entry point, CLI support, workflow coordination, offline mode, question count enforcement | All core modules |
| **`config.py`** | ‚öôÔ∏è **Configuration Hub** | OpenAI client setup, logging configuration, environment management | `openai`, `logging` |
| **`data_loader.py`** | üìÅ **Data Processing** | Multi-format file loading (CSV/Excel/JSON), safety limits, validation | `pandas`, `openpyxl` |
| **`data_analyzer.py`** | üîç **Dataset Analysis** | **Intelligent column analysis**, statistical insights, purpose detection | `pandas` |
| **`output_handler.py`** | üíæ **Report Generation** | Professional formatting, smart directory detection, export integration | `datetime`, `os` |
| **`emoji_utils.py`** | üé® **UI Enhancement** | Professional emoji system with automatic encoding detection & fallback | `sys`, `os` |
| **`export_utils.py`** | üì§ **Multi-Format Export** | Excel/JSON/HTML export functions, interactive dashboards | `pandas`, `json` |
| **`cli_handler.py`** | üñ•Ô∏è **CLI Interface** | Command-line arguments, config files, batch processing | `argparse`, `json` |

#### **ü§ñ AI & Agent Management**

| File | Purpose | Key Features | Dependencies |
|------|---------|--------------|--------------|
| **`agents.py`** | ü§ñ **CrewAI Agents** | Schema Sleuth & Question Genius agent definitions, GPT-4 integration | `crewai`, `langchain_openai` |
| **`tasks.py`** | üìã **Task Orchestration** | Dynamic task creation, **exact question count limiting**, validation workflows | `crewai` |
| **`smart_question_generator.py`** | üß† **SMART Engine** | Advanced question generation with diversity framework, enhanced context support | `openai`, `numpy`, `pandas` |
| **`smart_validator.py`** | ‚úÖ **Quality Control** | Multi-layer validation, SMART compliance scoring, quality thresholds | `dataclasses`, `re` |
| **`context_collector.py`** | üìù **Context Management** | 17 templates, 6 enhanced questions, intelligent quality ranges | `json`, `datetime` |

---

## üîß **Component Relationships**

### **üìä Data Flow Architecture**
```
User Input ‚Üí Hybrid Context Collection ‚Üí Data Loading ‚Üí Analysis ‚Üí AI Processing ‚Üí Validation ‚Üí Report Generation
     ‚Üë              ‚Üì                         ‚Üì             ‚Üì           ‚Üì             ‚Üì              ‚Üì
   main.py ‚Üí context_collector ‚Üí data_loader ‚Üí data_analyzer ‚Üí agents ‚Üí smart_validator ‚Üí output_handler
     ‚Üë              ‚Üì                         ‚Üì             ‚Üì           ‚Üì             ‚Üì              ‚Üì
  Offline Mode ‚Üí input/ folder ‚Üí fallback ‚Üí offline ‚Üí context-aware ‚Üí quality ‚Üí professional
```

### **ü§ñ AI Processing Pipeline**
```
Dataset Analysis ‚Üí Question Generation ‚Üí Quality Validation ‚Üí Report Formatting
       ‚Üì                    ‚Üì                   ‚Üì                    ‚Üì
  data_analyzer ‚Üí smart_question_generator ‚Üí smart_validator ‚Üí output_handler
       ‚Üë                    ‚Üë                   ‚Üë                    ‚Üë
   GPT-4 API         Diversity Framework    SMART Methodology    Professional Templates
       ‚Üë                    ‚Üë                   ‚Üë                    ‚Üë
  Offline Mode      Context-Aware Questions  Business Integration  Executive Focus
```

---

## üìã **File-by-File Documentation**

### **üéØ `main.py` - Application Entry Point**
```python
# Main workflow orchestration
def main():
    # 1. Hybrid context collection & validation
    # 2. Dataset loading & processing  
    # 3. AI agent creation & configuration
    # 4. Task execution & monitoring
    # 5. Quality validation & scoring
    # 6. Report generation & output
    # 7. Offline fallback mode handling
```

**Key Functions:**
- `check_dependencies()` - Validates Python version, API keys, required packages
- `get_smart_analysis_context()` - Hybrid context collection from input files
- `_detect_rate_limiting()` - Automatic offline mode detection
- `_generate_offline_results()` - Offline fallback with context-aware questions
- `main()` - Primary workflow coordinator

### **‚öôÔ∏è `config.py` - Configuration Management**
```python
# Core configuration settings
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

# Logging configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
```

**Responsibilities:**
- Environment variable management
- OpenAI client initialization
- Logging configuration
- System-wide constants

### **üìÅ `data_loader.py` - Data Processing Engine**
```python
class DataLoader:
    def load_dataset(self, file_path: str) -> pd.DataFrame:
        # Multi-format support: CSV, Excel, JSON
        # Encoding detection and handling
        # Error recovery and validation
        # Memory optimization
```

**Key Features:**
- **Multi-format Support**: CSV, XLSX, JSON
- **Encoding Detection**: UTF-8, UTF-8-BOM, CP1252
- **Error Handling**: Graceful failure recovery
- **Validation**: Data integrity checks

### **üîç `data_analyzer.py` - Intelligent Dataset Analysis**
```python
def _analyze_column_intelligently(column_name: str, series: pd.Series) -> str:
    # Intelligent column purpose detection
    # Statistical range analysis (min, max, avg, unique counts)
    # Type-specific insights generation
    # Context-aware descriptions
    
def generate_summary(df: pd.DataFrame) -> dict:
    # Intelligent column description generation (no GPT needed!)
    # Statistical summary creation
    # Data quality assessment
    # Business context integration
```

**Core Capabilities:**
- **Intelligent Column Analysis**: Auto-detects 15+ column types (Temporal, Financial, Identifiers, etc.)
- **Statistical Insights**: Min/Max/Avg/Unique counts with meaningful context
- **Purpose Detection**: Explains what each column is used for
- **No API Dependency**: Works 100% offline with intelligent analysis
- **Quality Assessment**: Completeness and validity checks

**Auto-Detected Column Types:**
- üìÖ Temporal (Year, Quarter, Month, Date)
- üí∞ Financial (Ratio, Revenue, Cost, Asset, Liability, Profit)
- üîë Identifiers (ID, Code, Carrier, Ticker)
- üìä Categorical (Category, Type, Status, Location)
- ‚úì Boolean (Flags, True/False fields)

### **ü§ñ `agents.py` - AI Agent Definitions**
```python
# Schema analysis agent
schema_sleuth = Agent(
    role='Data Structure Analyst',
    goal='Understand dataset structure and relationships',
    llm=gpt4_llm  # GPT-4 for premium quality
)

# Question generation agent  
question_genius = Agent(
    role='Analytical Question Generator',
    goal='Create insightful, SMART-compliant questions',
    llm=gpt4_llm
)
```

**Agent Responsibilities:**
- **Schema Sleuth**: Data structure analysis, relationship identification
- **Question Genius**: SMART question generation, context integration

### **üìã `tasks.py` - Task Management**
```python
def create_smart_tasks(datasets, schema_agent, question_agent, context, question_count):
    # Dynamic task creation based on datasets
    # SMART methodology integration
    # Quality validation workflows
    # Cross-dataset comparison tasks
```

**Task Types:**
- **Individual Analysis**: Dataset-specific question generation
- **Cross-Dataset**: Comparative analysis across multiple datasets
- **Validation**: Quality scoring and compliance checking

### **üß† `smart_question_generator.py` - Question Generation Engine**
```python
class SmartQuestionGenerator:
    def generate_enhanced_questions(self, dataset_name, df, context, num_questions):
        # Diversity framework implementation
        # Business-specific templates
        # SMART methodology compliance
        # Quality optimization
```

**Core Features:**
- **Diversity Framework**: 5 analytical categories
- **Business Templates**: Industry-specific approaches
- **SMART Compliance**: Methodology enforcement
- **Quality Optimization**: 97%+ score targeting

**Question Categories:**
1. **üìä Descriptive Analysis** - Statistical summaries, outlier identification
2. **üîç Comparative Analysis** - Benchmarking, segment comparison
3. **üìà Pattern Analysis** - Trends, forecasting, seasonality
4. **üéØ Business Impact** - Strategic insights, optimization
5. **üîó Relationship Discovery** - Correlations, causality

### **‚úÖ `smart_validator.py` - Quality Assurance**
```python
class SmartValidator:
    def validate_questions(self, questions, context):
        # Multi-layer quality scoring
        # SMART criteria validation  
        # Business relevance assessment
        # Diversity compliance checking
```

**Validation Layers:**
- **SMART Compliance**: 97% base score with component weighting
- **Clarity Assessment**: Readability and comprehension
- **Specificity Scoring**: Variable targeting and precision
- **Actionability Check**: Analytical verb usage
- **Relevance Validation**: Business context alignment

### **üìù `context_collector.py` - User Context Management**
```python
class DatasetContext:
    subject_area: str
    analysis_objectives: List[str]
    target_audience: str
    business_context: str
    time_sensitivity: str

def collect_context_hybrid():
    # 1. Read from input/ folder (Business_Background.txt, Dataset_Background.txt, message.txt)
    # 2. Fallback to interactive prompts if insufficient
    # 3. Combine for maximum context quality
```

**Hybrid Input System:**
- **Business_Background.txt** - Project context, objectives, audience
- **Dataset_Background.txt** - Dataset-specific context and details
- **message.txt** - Senior stakeholder instructions and strategic priorities
- **Interactive Fallback** - Traditional prompts if input files insufficient
- **Context Integration** - Combines file content with user preferences

**Context Templates:**
- **Financial Analysis** - Performance evaluation, risk assessment
- **Sales Analytics** - Pipeline analysis, performance tracking
- **Marketing Analytics** - Campaign effectiveness, segmentation
- **Operations** - Efficiency optimization, cost reduction
- **HR Analytics** - Performance analysis, retention
- **+ 12 additional industry templates**

### **üíæ `output_handler.py` - Report Generation**
```python
def save_separate_reports(datasets, results, context):
    # Professional formatting
    # Timestamped file naming
    # Structured output organization
    # Quality metrics integration
```

**Output Features:**
- **Professional Formatting**: Executive-ready reports
- **Dynamic Naming**: Context-based file naming
- **Quality Integration**: Comprehensive scoring display
- **Structured Organization**: Categorized output folders

---

## üìä **Configuration Files**

### **üìÑ `.env` - Environment Variables (Local Only)**
```bash
# Required (optional - offline mode available)
OPENAI_API_KEY=your_openai_api_key_here

# Optional
LOG_LEVEL=INFO
OUTPUT_DIRECTORY=Output
MAX_QUESTIONS_PER_DATASET=30
```

### **üìÑ `env.example` - Environment Template (GitHub)**
```bash
# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Optional Configuration
LOG_LEVEL=INFO
OUTPUT_DIRECTORY=Output
MAX_QUESTIONS_PER_DATASET=30

# Instructions:
# 1. Copy this file to .env
# 2. Replace 'your_openai_api_key_here' with your actual OpenAI API key
# 3. The .env file will be ignored by git for security
```

### **üìÑ `user_context.json` - User Preferences (Local Only)**
```json
[
  {
    "subject_area": "financial analysis",
    "analysis_objectives": ["performance evaluation", "risk assessment"],
    "target_audience": "executives",
    "business_context": "quarterly reporting",
    "time_sensitivity": "medium",
    "timestamp": "2025-01-08T14:30:00"
  }
]
```

### **üìÑ `.gitignore` - Git Ignore Rules (GitHub)**
```gitignore
# Virtual Environment
venv/
env/
ENV/

# Environment Variables
.env
.env.local
.env.production

# Python
__pycache__/
*.py[cod]
*$py.class

# Output files
Output/
*.txt
!requirements.txt

# User context (contains personal preferences)
user_context.json

# Input files (users should create their own)
input/Business_Background.txt
input/Dataset_Background.txt
input/message.txt
```

---

## üìà **Output Structure**

### **üìÇ `Output/` - Generated Reports (Local Only)**
```
Output/ (excluded from GitHub)
‚îú‚îÄ‚îÄ Individual_Financialanalysis_Riskassessmentriskas_Executives_2025-09-10_21-05.txt
‚îú‚îÄ‚îÄ Cross-Dataset_Financialanalysis_Riskassessmentriskas_Executives_2025-09-10_21-05.txt
‚îú‚îÄ‚îÄ Individual_Salesperformance_Riskassessment_Managers_2025-01-08_16-45.txt
‚îî‚îÄ‚îÄ Cross-Dataset_Salesperformance_Riskassessment_Managers_2025-01-08_16-45.txt
```

**Features:**
- ‚úÖ **Context-aware questions** with business background integration
- ‚úÖ **Executive-focused language** and strategic orientation
- ‚úÖ **Industry-specific terminology** and risk assessment focus
- ‚úÖ **Offline mode capability** with 100% reliability

**Naming Convention:**
- **Format**: `[Type]_[Focus]_[Objective]_[Audience]_[DateTime].txt`
- **Type**: Individual | Cross-Dataset
- **Focus**: Business domain (e.g., Financialanalysis, Salesperformance)
- **Objective**: Analysis goal (e.g., Performanceevaluation, Riskassessment)
- **Audience**: Target users (e.g., Executives, Managers, Analysts)
- **DateTime**: YYYY-MM-DD_HH-MM format

---

## üîÑ **Dependencies & Requirements**

### **Core Dependencies**
```
pandas>=1.5.0          # Data manipulation and analysis
openai>=1.0.0          # GPT-4 API integration
crewai>=0.1.0          # Multi-agent orchestration
langchain-openai       # LangChain OpenAI integration
numpy>=1.21.0          # Numerical computing
openpyxl>=3.0.0        # Excel file support
python-dotenv>=0.19.0  # Environment variable management
```

### **Python Version**
- **Minimum**: Python 3.13+
- **Recommended**: Python 3.13.7
- **OS Support**: Windows, macOS, Linux

---

## üõ†Ô∏è **Development Guidelines**

### **Code Organization**
- **Modular Design**: Each file has single responsibility
- **Clear Interfaces**: Well-defined function signatures
- **Error Handling**: Comprehensive exception management
- **Documentation**: Inline comments and docstrings

### **Quality Standards**
- **Type Hints**: All functions use type annotations
- **Error Recovery**: Graceful failure handling
- **Logging**: Comprehensive activity tracking
- **Validation**: Input/output validation throughout

### **Extension Points**
- **New Business Templates**: Add to `context_collector.py`
- **Additional File Formats**: Extend `data_loader.py`
- **Custom Validation**: Enhance `smart_validator.py`
- **Output Formats**: Modify `output_handler.py`

---

## üìã **Usage Patterns**

### **Standard Analysis Workflow**
1. **Hybrid Context Collection** ‚Üí Input files + interactive prompts
2. **Dataset Loading** ‚Üí Multi-file processing and validation
3. **AI Processing** ‚Üí Context-aware question generation and quality scoring
4. **Offline Fallback** ‚Üí Automatic fallback if API limits reached
5. **Report Generation** ‚Üí Professional output formatting

### **Customization Options**
- **Question Counts**: Configurable per dataset and cross-dataset
- **Business Context**: 17+ predefined templates + hybrid input system
- **Quality Thresholds**: Adjustable scoring criteria
- **Output Format**: Customizable report structure
- **Input System**: File-based context + interactive prompts
- **Offline Mode**: 100% reliability with context-aware fallback

### **Integration Points**
- **API Integration**: Extensible for BI tool integration
- **Batch Processing**: Multiple analysis session support
- **Export Formats**: Ready for downstream processing

---

**This structure enables Meta Minds to deliver professional-grade AI-powered data analysis with hybrid input system, offline fallback mode, context-aware question generation, and enterprise scalability.** üß†‚ú®